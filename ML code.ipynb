{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f95ad60",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0592ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pprint import pprint\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56b0ccbec712fe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Divisão do dataset em treino e em teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6117480d9ae682c9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = dataset.drop('Y', axis=1)\n",
    "y = dataset['Y']\n",
    "\n",
    "train_X, train_y, test_X, test_y= train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc0245b37f0844d",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed266105c8cfed50",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Modelos de ML\n",
    "A nossa task, prever o nivel de sinergia entre duas drogas, o que se trata de um problema de regressão, logo só poderemos utilizar modelos que se baseiem em regressão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169fca407762ef1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c6b13e5198d9f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=45, max_iter=1000)\n",
    "logreg.fit(train_X, train_y)\n",
    "\n",
    "print(f'Accuracy: {logreg.score(test_X, test_y):.2%}')\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "pred_y = logreg.predict(test_X)\n",
    "pprint(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a1d0de3024b60",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Confusion Matrix:')\n",
    "confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d69996aecbb78",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define metrics\n",
    "y_pred_proba = logreg.predict_proba(test_y)[::,1]\n",
    "fpr, tpr, _ = roc_curve(test_y,  y_pred_proba)\n",
    "auc = roc_auc_score(test_y, y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877cea12ab538e7d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d130271582afea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtree = DecisionTreeRegressor(random_state=45)\n",
    "dtree.fit(train_X, train_y)\n",
    "\n",
    "print(f'Accuracy: {dtree.score(test_X, test_y):.2%}')\n",
    "\n",
    "pred_y = dtree.predict(test_X)\n",
    "pprint(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d79bf703deb4d0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf2d86d8631826b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestRegressor(random_state=45)\n",
    "rfc.fit(train_X, train_y)\n",
    "\n",
    "print(f'Accuracy: {rfc.score(test_X, test_y):.2%}')\n",
    "\n",
    "pred_y = rfc.predict(test_X)\n",
    "pprint(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a920e00bda91af84",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## SVR (Support Vector Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39232e306108965",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "svr.fit(train_X, train_y)\n",
    "\n",
    "print(f'Accuracy: {svr.score(test_X, test_y):.2%}')\n",
    "\n",
    "pred_y = svr.predict(test_X)\n",
    "pprint(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fce14139f5ba20f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "IMPORTANTE: Podemos fazer como está em cima um de cada vez, ou entao, se quisermos treinar e testar todos os modelos de uma vez o prof usou isto na aula 10, ja pus os modelos que vi que deviamos usar, vejam se faz sentido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b95d767bd3e3b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(random_state=42, max_iter=1000),\n",
    "          DecisionTreeRegressor(random_state=42),\n",
    "          RandomForestRegressor(random_state=42),\n",
    "          SVR()]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(train_X, train_y)\n",
    "    print(model.__class__.__name__)\n",
    "    print('Accuracy on test set:', model.score(test_X, test_y))\n",
    "    print('Classification report:\\n', classification_report(test_y, model.predict(test_X)))\n",
    "    print('Confusion matrix:\\n', confusion_matrix(test_y, model.predict(test_X)))\n",
    "    print('ROC AUC score:', roc_auc_score(test_y, model.predict_proba(test_X)[::,1]))\n",
    "    print('-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a25621",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0885c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model validation\n",
    "\n",
    "# cross validation\n",
    "scores = cross_val_score(logreg, train_X, train_y, cv=5)\n",
    "print('Cross validation scores:', scores)\n",
    "print('Mean cross validation score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bfc6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap\n",
    "scores = []\n",
    "for i in range(1000):\n",
    "    X_boot, y_boot = resample(X_train, y_train)\n",
    "    logreg.fit(X_boot, y_boot)\n",
    "    scores.append(logreg.score(X_test, y_test))\n",
    "    \n",
    "print('Mean bootstrap score:', np.mean(scores))\n",
    "print('Standard deviation of bootstrap scores:', np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954b5c3f",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "We will use random search to find the best hyperparameters for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7569002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "# random forest hyperparameter tuning\n",
    "param_grid = {'n_estimators': [10, 100, 1000],\n",
    "              'max_depth': [None, 5, 10, 20],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4]}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rand_search = RandomizedSearchCV(rf, param_grid, cv=5, verbose=2, n_jobs=-1, n_iter=5)\n",
    "rand_search.fit(train_X, train_y)\n",
    "rand_search.best_params_, rand_search.best_score_, rand_search.best_estimator_.score(test_X, test_y)\n",
    "mse = mean_squared_error(test_X, pred_y)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "\n",
    "#grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "#grid_search.best_estimator_ # best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb4c43",
   "metadata": {},
   "source": [
    "## Save and load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb513f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model\n",
    "\n",
    "joblib.dump(rand_search.best_estimator_, 'best_model.pkl')\n",
    "\n",
    "# load the best model\n",
    "best_model = joblib.load('best_model.pkl')\n",
    "best_model.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8301a11b",
   "metadata": {},
   "source": [
    "## Model interpretation\n",
    "\n",
    "scikit-learn provides multiple methods for model interpretation. Here we will see feature importance and permutation importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ae9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model interpretation\n",
    "# feature importance\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_estimators=1000, max_depth=10, max_features='sqrt', min_samples_split=5, min_samples_leaf=2)\n",
    "rf.fit(train_X, train_y)\n",
    "rf.feature_importances_\n",
    "\n",
    "# plot feature importance\n",
    "importances = pd.Series(rf.feature_importances_, index=selected_columns)  #este selected columns vão ser as selecionadas na feature selection, mas como não está importado não lê esta variável\n",
    "importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance based on permutation importance\n",
    "\n",
    "perm_importance = permutation_importance(rf, test_X, test_y)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "plt.barh(selected_columns[sorted_idx[:10]], perm_importance.importances_mean[sorted_idx[:10]])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5cb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos_neg_idx = np.concatenate((sorted_idx[:10], sorted_idx[-10:]))\n",
    "plt.barh(selected_columns[pos_neg_idx], perm_importance.importances_mean[pos_neg_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
