{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f95ad60",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0592ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pprint import pprint\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071180f8",
   "metadata": {},
   "source": [
    "Nesta seccção iremos comparar o comportamento de diversos ML models no conjunto de dados, analisar o comportamento dos\n",
    "algoritmos calculando métricas de erro apropriadas e usando métodos de estimação do erro adequado. Por último pretendemos apresentar o melhor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d35f80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Y  drug1 MolWt  drug1 HeavyAtomMolWt  drug1 ExactMolWt  \\\n",
      "0       7.693530     4.552044              4.441072          4.549836   \n",
      "1       7.778053     4.552044              4.441072          4.549836   \n",
      "2      -1.198505     4.552044              4.441072          4.549836   \n",
      "3       2.595684     4.552044              4.441072          4.549836   \n",
      "4      -5.139971     4.552044              4.441072          4.549836   \n",
      "...          ...          ...                   ...               ...   \n",
      "19861  10.223066     5.948467              5.475267          5.944298   \n",
      "19862  20.551627     5.948467              5.475267          5.944298   \n",
      "19863  12.190316     5.948467              5.475267          5.944298   \n",
      "19864  23.438547     5.948467              5.475267          5.944298   \n",
      "19865  12.223791     5.948467              5.475267          5.944298   \n",
      "\n",
      "       drug1 BertzCT  drug1 TPSA  morgan drug1 15  morgan drug1 33  \\\n",
      "0          11.258666    2.190289              0.0              0.0   \n",
      "1          11.258666    2.190289              0.0              0.0   \n",
      "2          11.258666    2.190289              0.0              0.0   \n",
      "3          11.258666    2.190289              0.0              0.0   \n",
      "4          11.258666    2.190289              0.0              0.0   \n",
      "...              ...         ...              ...              ...   \n",
      "19861       8.967280    1.585104              0.0              0.0   \n",
      "19862       8.967280    1.585104              0.0              0.0   \n",
      "19863       8.967280    1.585104              0.0              0.0   \n",
      "19864       8.967280    1.585104              0.0              0.0   \n",
      "19865       8.967280    1.585104              0.0              0.0   \n",
      "\n",
      "       morgan drug1 36  morgan drug1 64  ...  Parametro 8775  Parametro 8776  \\\n",
      "0                  0.0              0.0  ...        0.933708        0.433194   \n",
      "1                  0.0              0.0  ...        0.453011        0.868781   \n",
      "2                  0.0              0.0  ...       -0.367088       -0.495932   \n",
      "3                  0.0              0.0  ...        0.852838       -0.152449   \n",
      "4                  0.0              0.0  ...       -1.854093       -2.383995   \n",
      "...                ...              ...  ...             ...             ...   \n",
      "19861              0.0              1.0  ...        0.989373        0.598182   \n",
      "19862              0.0              1.0  ...        0.159920        0.157617   \n",
      "19863              0.0              1.0  ...        0.159920        0.157617   \n",
      "19864              0.0              1.0  ...        0.345755        0.172750   \n",
      "19865              0.0              1.0  ...       -1.854094       -2.383994   \n",
      "\n",
      "       Parametro 8777  Parametro 8778  Parametro 8779  Parametro 8780  \\\n",
      "0           -0.705877       -0.797751        0.494978       -0.239587   \n",
      "1           -0.548668        1.191511        0.947887        0.393898   \n",
      "2           -0.639091       -0.346006       -0.034777       -1.268040   \n",
      "3           -0.653551        0.369509       -0.358118        1.586969   \n",
      "4            0.068724       -0.583244       -2.238896       -1.288220   \n",
      "...               ...             ...             ...             ...   \n",
      "19861       -0.708544       -0.494359       -0.540534       -0.977627   \n",
      "19862        2.134676        2.314793        0.981662       -0.019900   \n",
      "19863        2.134676        2.314793        0.981662       -0.019900   \n",
      "19864       -0.672222       -0.729491        0.774517        0.535449   \n",
      "19865        0.068701       -0.583185       -2.238896       -1.288246   \n",
      "\n",
      "       Parametro 8781  Parametro 8782  Parametro 8783  Parametro 8784  \n",
      "0            1.279730        0.691891       -0.982503       -0.364565  \n",
      "1            1.241226        1.139293       -1.070203       -0.425415  \n",
      "2           -0.277364       -0.423137       -1.065120       -1.002490  \n",
      "3            1.275677        0.621267       -0.365272       -0.818869  \n",
      "4           -1.650908       -1.705543       -0.714340        0.635244  \n",
      "...               ...             ...             ...             ...  \n",
      "19861       -0.762502        0.882945       -1.073682        0.481022  \n",
      "19862        0.278455       -0.374227       -0.073559       -0.217856  \n",
      "19863        0.278455       -0.374227       -0.073559       -0.217856  \n",
      "19864        0.406174       -0.436593        1.207464       -1.522136  \n",
      "19865       -1.650914       -1.705541       -0.714347        0.635266  \n",
      "\n",
      "[19866 rows x 8775 columns]\n"
     ]
    }
   ],
   "source": [
    "path=\"C:\\\\Users\\\\guilh\\\\OneDrive - Universidade de Aveiro\\\\Guilherme\\\\dataset.csv\"\n",
    "data=pd.read_csv(path)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c9dc0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug1 MolWt</th>\n",
       "      <th>drug1 HeavyAtomMolWt</th>\n",
       "      <th>drug1 ExactMolWt</th>\n",
       "      <th>drug1 BertzCT</th>\n",
       "      <th>drug1 TPSA</th>\n",
       "      <th>morgan drug1 15</th>\n",
       "      <th>morgan drug1 33</th>\n",
       "      <th>morgan drug1 36</th>\n",
       "      <th>morgan drug1 64</th>\n",
       "      <th>morgan drug1 80</th>\n",
       "      <th>...</th>\n",
       "      <th>Parametro 8775</th>\n",
       "      <th>Parametro 8776</th>\n",
       "      <th>Parametro 8777</th>\n",
       "      <th>Parametro 8778</th>\n",
       "      <th>Parametro 8779</th>\n",
       "      <th>Parametro 8780</th>\n",
       "      <th>Parametro 8781</th>\n",
       "      <th>Parametro 8782</th>\n",
       "      <th>Parametro 8783</th>\n",
       "      <th>Parametro 8784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.552044</td>\n",
       "      <td>4.441072</td>\n",
       "      <td>4.549836</td>\n",
       "      <td>11.258666</td>\n",
       "      <td>2.190289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933708</td>\n",
       "      <td>0.433194</td>\n",
       "      <td>-0.705877</td>\n",
       "      <td>-0.797751</td>\n",
       "      <td>0.494978</td>\n",
       "      <td>-0.239587</td>\n",
       "      <td>1.279730</td>\n",
       "      <td>0.691891</td>\n",
       "      <td>-0.982503</td>\n",
       "      <td>-0.364565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.552044</td>\n",
       "      <td>4.441072</td>\n",
       "      <td>4.549836</td>\n",
       "      <td>11.258666</td>\n",
       "      <td>2.190289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453011</td>\n",
       "      <td>0.868781</td>\n",
       "      <td>-0.548668</td>\n",
       "      <td>1.191511</td>\n",
       "      <td>0.947887</td>\n",
       "      <td>0.393898</td>\n",
       "      <td>1.241226</td>\n",
       "      <td>1.139293</td>\n",
       "      <td>-1.070203</td>\n",
       "      <td>-0.425415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.552044</td>\n",
       "      <td>4.441072</td>\n",
       "      <td>4.549836</td>\n",
       "      <td>11.258666</td>\n",
       "      <td>2.190289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.367088</td>\n",
       "      <td>-0.495932</td>\n",
       "      <td>-0.639091</td>\n",
       "      <td>-0.346006</td>\n",
       "      <td>-0.034777</td>\n",
       "      <td>-1.268040</td>\n",
       "      <td>-0.277364</td>\n",
       "      <td>-0.423137</td>\n",
       "      <td>-1.065120</td>\n",
       "      <td>-1.002490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.552044</td>\n",
       "      <td>4.441072</td>\n",
       "      <td>4.549836</td>\n",
       "      <td>11.258666</td>\n",
       "      <td>2.190289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852838</td>\n",
       "      <td>-0.152449</td>\n",
       "      <td>-0.653551</td>\n",
       "      <td>0.369509</td>\n",
       "      <td>-0.358118</td>\n",
       "      <td>1.586969</td>\n",
       "      <td>1.275677</td>\n",
       "      <td>0.621267</td>\n",
       "      <td>-0.365272</td>\n",
       "      <td>-0.818869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.552044</td>\n",
       "      <td>4.441072</td>\n",
       "      <td>4.549836</td>\n",
       "      <td>11.258666</td>\n",
       "      <td>2.190289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.854093</td>\n",
       "      <td>-2.383995</td>\n",
       "      <td>0.068724</td>\n",
       "      <td>-0.583244</td>\n",
       "      <td>-2.238896</td>\n",
       "      <td>-1.288220</td>\n",
       "      <td>-1.650908</td>\n",
       "      <td>-1.705543</td>\n",
       "      <td>-0.714340</td>\n",
       "      <td>0.635244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19861</th>\n",
       "      <td>5.948467</td>\n",
       "      <td>5.475267</td>\n",
       "      <td>5.944298</td>\n",
       "      <td>8.967280</td>\n",
       "      <td>1.585104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989373</td>\n",
       "      <td>0.598182</td>\n",
       "      <td>-0.708544</td>\n",
       "      <td>-0.494359</td>\n",
       "      <td>-0.540534</td>\n",
       "      <td>-0.977627</td>\n",
       "      <td>-0.762502</td>\n",
       "      <td>0.882945</td>\n",
       "      <td>-1.073682</td>\n",
       "      <td>0.481022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19862</th>\n",
       "      <td>5.948467</td>\n",
       "      <td>5.475267</td>\n",
       "      <td>5.944298</td>\n",
       "      <td>8.967280</td>\n",
       "      <td>1.585104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159920</td>\n",
       "      <td>0.157617</td>\n",
       "      <td>2.134676</td>\n",
       "      <td>2.314793</td>\n",
       "      <td>0.981662</td>\n",
       "      <td>-0.019900</td>\n",
       "      <td>0.278455</td>\n",
       "      <td>-0.374227</td>\n",
       "      <td>-0.073559</td>\n",
       "      <td>-0.217856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19863</th>\n",
       "      <td>5.948467</td>\n",
       "      <td>5.475267</td>\n",
       "      <td>5.944298</td>\n",
       "      <td>8.967280</td>\n",
       "      <td>1.585104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159920</td>\n",
       "      <td>0.157617</td>\n",
       "      <td>2.134676</td>\n",
       "      <td>2.314793</td>\n",
       "      <td>0.981662</td>\n",
       "      <td>-0.019900</td>\n",
       "      <td>0.278455</td>\n",
       "      <td>-0.374227</td>\n",
       "      <td>-0.073559</td>\n",
       "      <td>-0.217856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>5.948467</td>\n",
       "      <td>5.475267</td>\n",
       "      <td>5.944298</td>\n",
       "      <td>8.967280</td>\n",
       "      <td>1.585104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345755</td>\n",
       "      <td>0.172750</td>\n",
       "      <td>-0.672222</td>\n",
       "      <td>-0.729491</td>\n",
       "      <td>0.774517</td>\n",
       "      <td>0.535449</td>\n",
       "      <td>0.406174</td>\n",
       "      <td>-0.436593</td>\n",
       "      <td>1.207464</td>\n",
       "      <td>-1.522136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19865</th>\n",
       "      <td>5.948467</td>\n",
       "      <td>5.475267</td>\n",
       "      <td>5.944298</td>\n",
       "      <td>8.967280</td>\n",
       "      <td>1.585104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.854094</td>\n",
       "      <td>-2.383994</td>\n",
       "      <td>0.068701</td>\n",
       "      <td>-0.583185</td>\n",
       "      <td>-2.238896</td>\n",
       "      <td>-1.288246</td>\n",
       "      <td>-1.650914</td>\n",
       "      <td>-1.705541</td>\n",
       "      <td>-0.714347</td>\n",
       "      <td>0.635266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19866 rows × 8774 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       drug1 MolWt  drug1 HeavyAtomMolWt  drug1 ExactMolWt  drug1 BertzCT  \\\n",
       "0         4.552044              4.441072          4.549836      11.258666   \n",
       "1         4.552044              4.441072          4.549836      11.258666   \n",
       "2         4.552044              4.441072          4.549836      11.258666   \n",
       "3         4.552044              4.441072          4.549836      11.258666   \n",
       "4         4.552044              4.441072          4.549836      11.258666   \n",
       "...            ...                   ...               ...            ...   \n",
       "19861     5.948467              5.475267          5.944298       8.967280   \n",
       "19862     5.948467              5.475267          5.944298       8.967280   \n",
       "19863     5.948467              5.475267          5.944298       8.967280   \n",
       "19864     5.948467              5.475267          5.944298       8.967280   \n",
       "19865     5.948467              5.475267          5.944298       8.967280   \n",
       "\n",
       "       drug1 TPSA  morgan drug1 15  morgan drug1 33  morgan drug1 36  \\\n",
       "0        2.190289              0.0              0.0              0.0   \n",
       "1        2.190289              0.0              0.0              0.0   \n",
       "2        2.190289              0.0              0.0              0.0   \n",
       "3        2.190289              0.0              0.0              0.0   \n",
       "4        2.190289              0.0              0.0              0.0   \n",
       "...           ...              ...              ...              ...   \n",
       "19861    1.585104              0.0              0.0              0.0   \n",
       "19862    1.585104              0.0              0.0              0.0   \n",
       "19863    1.585104              0.0              0.0              0.0   \n",
       "19864    1.585104              0.0              0.0              0.0   \n",
       "19865    1.585104              0.0              0.0              0.0   \n",
       "\n",
       "       morgan drug1 64  morgan drug1 80  ...  Parametro 8775  Parametro 8776  \\\n",
       "0                  0.0              0.0  ...        0.933708        0.433194   \n",
       "1                  0.0              0.0  ...        0.453011        0.868781   \n",
       "2                  0.0              0.0  ...       -0.367088       -0.495932   \n",
       "3                  0.0              0.0  ...        0.852838       -0.152449   \n",
       "4                  0.0              0.0  ...       -1.854093       -2.383995   \n",
       "...                ...              ...  ...             ...             ...   \n",
       "19861              1.0              1.0  ...        0.989373        0.598182   \n",
       "19862              1.0              1.0  ...        0.159920        0.157617   \n",
       "19863              1.0              1.0  ...        0.159920        0.157617   \n",
       "19864              1.0              1.0  ...        0.345755        0.172750   \n",
       "19865              1.0              1.0  ...       -1.854094       -2.383994   \n",
       "\n",
       "       Parametro 8777  Parametro 8778  Parametro 8779  Parametro 8780  \\\n",
       "0           -0.705877       -0.797751        0.494978       -0.239587   \n",
       "1           -0.548668        1.191511        0.947887        0.393898   \n",
       "2           -0.639091       -0.346006       -0.034777       -1.268040   \n",
       "3           -0.653551        0.369509       -0.358118        1.586969   \n",
       "4            0.068724       -0.583244       -2.238896       -1.288220   \n",
       "...               ...             ...             ...             ...   \n",
       "19861       -0.708544       -0.494359       -0.540534       -0.977627   \n",
       "19862        2.134676        2.314793        0.981662       -0.019900   \n",
       "19863        2.134676        2.314793        0.981662       -0.019900   \n",
       "19864       -0.672222       -0.729491        0.774517        0.535449   \n",
       "19865        0.068701       -0.583185       -2.238896       -1.288246   \n",
       "\n",
       "       Parametro 8781  Parametro 8782  Parametro 8783  Parametro 8784  \n",
       "0            1.279730        0.691891       -0.982503       -0.364565  \n",
       "1            1.241226        1.139293       -1.070203       -0.425415  \n",
       "2           -0.277364       -0.423137       -1.065120       -1.002490  \n",
       "3            1.275677        0.621267       -0.365272       -0.818869  \n",
       "4           -1.650908       -1.705543       -0.714340        0.635244  \n",
       "...               ...             ...             ...             ...  \n",
       "19861       -0.762502        0.882945       -1.073682        0.481022  \n",
       "19862        0.278455       -0.374227       -0.073559       -0.217856  \n",
       "19863        0.278455       -0.374227       -0.073559       -0.217856  \n",
       "19864        0.406174       -0.436593        1.207464       -1.522136  \n",
       "19865       -1.650914       -1.705541       -0.714347        0.635266  \n",
       "\n",
       "[19866 rows x 8774 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data[\"Y\"]\n",
    "X = data.drop('Y', axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d40be6e",
   "metadata": {},
   "source": [
    "Divir o dataset em 70 % treino , 15 % validação e 15% teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4478c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56b0ccbec712fe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Divisão do dataset em treino, validação e teste.\n",
    "Agora o que nos interessa é :\n",
    "\n",
    "X_train, y_train;\n",
    "\n",
    "X_val, y_val;\n",
    "\n",
    "X_test,y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa619c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1123     36.599969\n",
       "6659      6.689280\n",
       "14040    -1.964928\n",
       "8455    -10.739940\n",
       "9710      3.982901\n",
       "           ...    \n",
       "16637    24.221914\n",
       "934      -8.532292\n",
       "2404     -5.741128\n",
       "17583     6.112842\n",
       "878      -7.257895\n",
       "Name: Y, Length: 2980, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed266105c8cfed50",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Modelos de ML\n",
    "A nossa task, prever o nivel de sinergia entre duas drogas, o que se trata de um problema de regressão, logo só poderemos utilizar modelos que se baseiem em regressão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169fca407762ef1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Logistical Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f2c05",
   "metadata": {},
   "source": [
    "Um modelo de regressão logística modela a relação entre as variáveis independentes e a probabilidade de pertencer a uma determinada classe usando uma função logística. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8805998d",
   "metadata": {},
   "source": [
    "Aqui os hiperparâmetros estão definidos, mas podiamos fazer algo para determinar a melhro combinação.\n",
    "\n",
    "Depois de cada modelo já feito com parâmetreos definidos teoricamente, tem outro exemplo com a exploração dos melhores hiperparâmetros. Para discutir a melhor abordagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3510e4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Mean Squared Error (Validation): 408.23\n",
      "KNN - Mean Squared Error (Validation): 391.93\n",
      "Decision Tree - Mean Squared Error (Validation): 566.49\n",
      "Random Forest - Mean Squared Error (Validation): 251.76\n",
      "\n",
      "Melhor Modelo Escolhido:\n",
      "Model                  Random Forest\n",
      "Mean Squared Error        251.759894\n",
      "R-squared                   0.458749\n",
      "Mean Absolute Error        10.177774\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "models_to_try = [\n",
    "    ('Linear Regression', LinearRegression()),\n",
    "    ('KNN', KNeighborsRegressor()),\n",
    "    ('Decision Tree', DecisionTreeRegressor()),\n",
    "    ('Random Forest', RandomForestRegressor())\n",
    "    #('SVM', SVR()),  # Support Vector Machine para regressão\n",
    "    #('AdaBoost', AdaBoostRegressor())\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models_to_try:\n",
    "    # Treinamento do modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Avaliação do desempenho no conjunto de validação\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Cálculo das métricas\n",
    "    mse_val = mean_squared_error(y_test, y_test_pred)\n",
    "    r2_val = r2_score(y_test, y_test_pred)\n",
    "    mae_val = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    # Armazenar resultados em um dicionário\n",
    "    model_results = {\n",
    "        'Model': model_name,\n",
    "        'Mean Squared Error': mse_val,\n",
    "        'R-squared': r2_val,\n",
    "        'Mean Absolute Error': mae_val,\n",
    "    }\n",
    "    \n",
    "    # Adicionar os resultados à lista\n",
    "    results.append(model_results)\n",
    "\n",
    "    # Exibição dos resultados\n",
    "    print(f'{model_name} - Mean Squared Error (Validation): {mse_val:.2f}')\n",
    "\n",
    "# Converter a lista de resultados em um DataFrame do pandas (opcional)\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Encontrar o modelo com o menor MSE\n",
    "best_model_df = results_df.loc[results_df['Mean Squared Error'].idxmin()]\n",
    "\n",
    "# Exibir o melhor modelo\n",
    "print(f'\\nMelhor Modelo Escolhido:')\n",
    "print(best_model_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6953dc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Model': 'Linear Regression',\n",
       "  'Mean Squared Error': 408.2329743671923,\n",
       "  'R-squared': 0.12235183198607524,\n",
       "  'Mean Absolute Error': 14.072671672404226},\n",
       " {'Model': 'KNN',\n",
       "  'Mean Squared Error': 391.9258701801778,\n",
       "  'R-squared': 0.1574099997823699,\n",
       "  'Mean Absolute Error': 13.335788427795746},\n",
       " {'Model': 'Decision Tree',\n",
       "  'Mean Squared Error': 566.4933787850647,\n",
       "  'R-squared': -0.21788759679058023,\n",
       "  'Mean Absolute Error': 15.047101666279918},\n",
       " {'Model': 'Random Forest',\n",
       "  'Mean Squared Error': 251.75989428147605,\n",
       "  'R-squared': 0.45874874429723667,\n",
       "  'Mean Absolute Error': 10.177774430809903}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eded57b3",
   "metadata": {},
   "source": [
    "# ensemble voting (a fazer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f359f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Escolha os modelos que deseja incluir no ensemble\n",
    "model_linear = LinearRegression()\n",
    "model_rf = RandomForestRegressor()\n",
    "model_svm = SVR()\n",
    "\n",
    "# Crie um ensemble utilizando a média das previsões dos modelos\n",
    "ensemble_model = VotingRegressor(estimators=[\n",
    "    ('Linear Regression', model_linear),\n",
    "    ('Random Forest', model_rf),\n",
    "    ('SVM', model_svm)\n",
    "])\n",
    "\n",
    "# Treine o ensemble\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Faça previsões usando o ensemble\n",
    "y_pred_ensemble = ensemble_model.predict(X_test)\n",
    "\n",
    "# Avalie o desempenho do ensemble\n",
    "mse_ensemble = mean_squared_error(y_test, y_pred_ensemble)\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble)\n",
    "mae_ensemble = mean_absolute_error(y_test, y_pred_ensemble)\n",
    "\n",
    "# Exiba os resultados do ensemble\n",
    "print(f'Ensemble - Mean Squared Error (Validation): {mse_ensemble:.2f}')\n",
    "print(f'Ensemble - R-squared (Validation): {r2_ensemble:.2f}')\n",
    "print(f'Ensemble - Mean Absolute Error (Validation): {mae_ensemble:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1feb88",
   "metadata": {},
   "source": [
    "# ensemble stacking (a fazer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c93d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca24e885",
   "metadata": {},
   "source": [
    "# daqui pra baixo ainda nao é para fazer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3569e8d9",
   "metadata": {},
   "source": [
    "#### Com exploração de hiperparâmetros para determinar a melhor combinação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d78cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os hiperparâmetros \n",
    "parameters = {\n",
    "    'penalty': ['l1', 'l2', 'none'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'lbfgs', 'saga'],\n",
    "    'max_iter': [10,100, 200]\n",
    "}\n",
    "\n",
    "# Criar o modelo de regressão logística\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Criar o objeto GridSearchCV\n",
    "grid_search = GridSearchCV(logistic_regression, parameters, scoring='f1', cv=5)\n",
    "\n",
    "# Executar a busca em grid para encontrar os melhores hiperparâmetros\n",
    "grid_search.fit(train_X[:, 3:], train_y)  #FUI USANDO SEMPRE [:, 3:] (todas as linhas e descartando as 3 primeiras colunas) MAS NÃO ESTOU A VER NO DATASET QUAIS COLUNAS INCLUIR, POR ISSO QUANDO SE TIVER O DATASET TEM QUE SE ADAPTAR ISTO EM TODOS ABAIXO\n",
    "\n",
    "# Obter os melhores hiperparâmetros encontrados\n",
    "best_params_LT = grid_search.best_params_\n",
    "best_params_LT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7842f4",
   "metadata": {},
   "source": [
    "#### Com exploração de hiperparâmetros para determinar a melhor combinação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b74c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hiperparametros\n",
    "parameters = {\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(dt_classifier, parameters, scoring='f1', cv=5)\n",
    "grid_search.fit(X_tr[:, 3:], train_y)\n",
    "\n",
    "best_params_DT = grid_search.best_params_\n",
    "best_params_DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a5e4e",
   "metadata": {},
   "source": [
    "#### Com exploração de hiperparâmetros para determinar a melhor combinação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a920e00bda91af84",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## SVR (Support Vector Regression)\n",
    "\n",
    "O SVR é uma técnica de ML para regressão, baseada em Support Vector Machines (SVM), que procura prever valores contínuos ao otimizar uma função de margem de erro entre as previsões do modelo e os valores reais dos dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39232e306108965",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "svr.fit(train_X, train_y)\n",
    "\n",
    "print(f'Accuracy: {svr.score(test_X, test_y):.2%}')\n",
    "\n",
    "pred_y = svr.predict(test_X)\n",
    "pprint(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a96dd",
   "metadata": {},
   "source": [
    "#### Com exploração de hiperparâmetros para determinar a melhor combinação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac9c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os parâmetros a ajustar para SVR\n",
    "parameters_svr = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1],\n",
    "    'epsilon': [0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# Criar o regressor SVR\n",
    "SVR_regressor = SVR()\n",
    "\n",
    "# Criar o objeto GridSearchCV\n",
    "grid_search_svr = GridSearchCV(SVR_regressor, parameters_svr, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Executar o grid search usando os dados de treino (X_tr e y_tr)\n",
    "grid_search.fit(train_X[:, 3:], train_y)\n",
    "\n",
    "# Obter os melhores parâmetros\n",
    "best_params_SVR = grid_search.best_params_\n",
    "best_params_SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TREINO\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Supondo que você tenha um conjunto de dados train_X, train_y\n",
    "# e que 'best_params_SVM' contenha os melhores hiperparâmetros obtidos\n",
    "\n",
    "# Criar um objeto MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Definir os parâmetros a ajustar para SVM\n",
    "parameters_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1],\n",
    "    'degree': [2, 3, 4],\n",
    "}\n",
    "\n",
    "# Criar o classificador SVM\n",
    "SVM_classifier = SVC()\n",
    "\n",
    "# Criar o objeto GridSearchCV\n",
    "grid_search_svm = GridSearchCV(SVM_classifier, parameters_svm, scoring='accuracy', cv=5)\n",
    "\n",
    "# Dividir os dados usando StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in sss.split(train_X, train_y):\n",
    "    X_SVM_train, X_SVM_test, y_SVM_train, y_SVM_test = train_X[train_index, 3:], train_X[test_index, 3:], train_y[train_index], train_y[test_index]\n",
    "    \n",
    "    # Normalizar os dados\n",
    "    X_SVM_train_new = min_max_scaler.fit_transform(X_SVM_train)\n",
    "    X_SVM_test_new = min_max_scaler.transform(X_SVM_test)\n",
    "    \n",
    "    # Executar o grid search usando os dados de treino\n",
    "    grid_search_svm.fit(X_SVM_train_new, y_SVM_train)\n",
    "\n",
    "    # Obter os melhores parâmetros\n",
    "    best_params_SVM = grid_search_svm.best_params_\n",
    "    \n",
    "    # Criar o modelo SVM com os melhores hiperparâmetros\n",
    "    SVM_classifier = SVC(**best_params_SVM)\n",
    "    \n",
    "    # Treinar o modelo\n",
    "    SVM_classifier.fit(X_SVM_train_new, y_SVM_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac4566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avaliação\n",
    "X_new = train_X[:,3:]\n",
    "X_new = min_max_scaler.fit_transform(X_new)\n",
    "KN_classifier.fit(X_new, y_tr)\n",
    "y_tr_predict = KN_classifier.predict(X_new)\n",
    "print('f1 on Train set: ', f1_score(y_tr, y_tr_predict))\n",
    "print('MCC on Train set: ', matthews_corrcoef(y_tr, y_tr_predict))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_tr, y_tr_predict).ravel()\n",
    "print(\"tn, fp, tp, fn\", tn, fp, tp, fn)\n",
    "specificity = tn / (tn+fp)\n",
    "print('Specificity on Train set(tn / (tn+fp)): ', specificity)\n",
    "sensitivity = tp / (tp+fn)\n",
    "print('Sensitivity on Train set(tp / (tp+fn)): ', sensitivity)\n",
    "accuracy = (tp+tn) /(tp+tn+fp+fn)\n",
    "print('Accuracy on Train set: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27132d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTE\n",
    "\n",
    "X_te_new = test_X[:,3:]\n",
    "\n",
    "X_te_new = min_max_scaler.transform(X_te_new)\n",
    "\n",
    "y_SVM_pred = KN_classifier.predict(X_te_new)\n",
    "\n",
    "print(\"*************************************\")\n",
    "print('f1 on Test set: ', f1_score(y_te, y_SVM_pred))\n",
    "print('MCC on Test set: ', matthews_corrcoef(y_te, y_SVM_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_te, y_SVM_pred).ravel()\n",
    "print(\"tn, fp, tp, fn\", tn, fp, tp, fn)\n",
    "specificity = tn / (tn + fp)\n",
    "print('Specificity on Test set(tn / (tn+fp)): ', specificity)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print('Sensitivity on Test set(tp / (tp+fn)): ', sensitivity)\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print('Accuracy on Test set: ', accuracy)\n",
    "precision=tp/(tp+fp)\n",
    "print(\"Precision on Test set: \", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "\n",
    "# Calcula a matriz de confusão\n",
    "confusion = confusion_matrix(y_te, y_SVM_pred)\n",
    "\n",
    "# Obtém os valores dos verdadeiros positivos (tp), verdadeiros negativos (tn),\n",
    "# falsos positivos (fp) e falsos negativos (fn)\n",
    "tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "# Imprime os valores da matriz de confusão\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Plota a matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, cmap='Greens', fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a25621",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0885c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model validation\n",
    "\n",
    "# cross validation\n",
    "scores = cross_val_score(logreg, train_X, train_y, cv=5)\n",
    "print('Cross validation scores:', scores)\n",
    "print('Mean cross validation score:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bfc6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap\n",
    "scores = []\n",
    "for i in range(1000):\n",
    "    X_boot, y_boot = resample(X_train, y_train)\n",
    "    logreg.fit(X_boot, y_boot)\n",
    "    scores.append(logreg.score(X_test, y_test))\n",
    "    \n",
    "print('Mean bootstrap score:', np.mean(scores))\n",
    "print('Standard deviation of bootstrap scores:', np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954b5c3f",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "We will use random search to find the best hyperparameters for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7569002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "# random forest hyperparameter tuning\n",
    "param_grid = {'n_estimators': [10, 100, 1000],\n",
    "              'max_depth': [None, 5, 10, 20],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4]}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rand_search = RandomizedSearchCV(rf, param_grid, cv=5, verbose=2, n_jobs=-1, n_iter=5)\n",
    "rand_search.fit(train_X, train_y)\n",
    "rand_search.best_params_, rand_search.best_score_, rand_search.best_estimator_.score(test_X, test_y)\n",
    "mse = mean_squared_error(test_X, pred_y)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "\n",
    "#grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "#grid_search.best_estimator_ # best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb4c43",
   "metadata": {},
   "source": [
    "## Save and load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb513f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model\n",
    "\n",
    "joblib.dump(rand_search.best_estimator_, 'best_model.pkl')\n",
    "\n",
    "# load the best model\n",
    "best_model = joblib.load('best_model.pkl')\n",
    "best_model.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8301a11b",
   "metadata": {},
   "source": [
    "## Model interpretation\n",
    "\n",
    "scikit-learn provides multiple methods for model interpretation. Here we will see feature importance and permutation importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ae9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model interpretation\n",
    "# feature importance\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_estimators=1000, max_depth=10, max_features='sqrt', min_samples_split=5, min_samples_leaf=2)\n",
    "rf.fit(train_X, train_y)\n",
    "rf.feature_importances_\n",
    "\n",
    "# plot feature importance\n",
    "importances = pd.Series(rf.feature_importances_, index=selected_columns)  #este selected columns vão ser as selecionadas na feature selection, mas como não está importado não lê esta variável\n",
    "importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance based on permutation importance\n",
    "\n",
    "perm_importance = permutation_importance(rf, test_X, test_y)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "plt.barh(selected_columns[sorted_idx[:10]], perm_importance.importances_mean[sorted_idx[:10]])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5cb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos_neg_idx = np.concatenate((sorted_idx[:10], sorted_idx[-10:]))\n",
    "plt.barh(selected_columns[pos_neg_idx], perm_importance.importances_mean[pos_neg_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
